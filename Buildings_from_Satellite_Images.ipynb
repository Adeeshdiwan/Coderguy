{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Adeeshdiwan/Coderguy/blob/master/Buildings_from_Satellite_Images.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "_uuid": "59f327c1-c0c2-4bac-bb8f-dd4afddbfdd7",
        "_cell_guid": "a048655e-6cd3-40b7-ad21-14376be88acf",
        "trusted": true,
        "id": "IP3LeCdoFAOh"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "992ab790-a009-4829-a25e-2fe33b0e413b",
        "_cell_guid": "a019a73e-cd9d-421e-a219-732e3b2e9929",
        "trusted": true,
        "id": "5q_ZevbHFAOq"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import numba as nb\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data\n",
        "import gdal\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import random\n",
        "\n",
        "import os\n",
        "import gc\n",
        "\n",
        "DATAPATH = \"/kaggle/input/sysu-rs-contest-2021/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c0e34983-c49a-4913-9126-455f289c921d",
        "_cell_guid": "913a9587-0b1c-48c9-8faa-d15f78d973f6",
        "trusted": true,
        "id": "zSnzj0W0FAOt"
      },
      "cell_type": "code",
      "source": [
        "class myDataset(data.Dataset):\n",
        "    def __init__(self, data_path, set_name, val_rate=0.1):\n",
        "        self.set_name = set_name\n",
        "        self.imageList, self.labelList = [], []\n",
        "        folderList = [(data_path + \"/train/\" + i) for i in [\"rural_CN\", \"urban_CN\", \"urban_US\"]]\n",
        "        for fd in folderList:\n",
        "            self.imageList.extend([i.path for i in os.scandir(fd + \"/image\")])\n",
        "        self.labelList = [i.replace(\"image\", \"label\") for i in self.imageList]\n",
        "\n",
        "        total_num = len(self.imageList)\n",
        "        val_num = int(total_num * val_rate)\n",
        "\n",
        "        np.random.seed(0)\n",
        "        val_index = np.random.choice(np.arange(total_num), size=val_num, replace=False).astype(np.int)\n",
        "        train_index = np.array(list(set(np.arange(total_num, dtype=np.int)) - set(val_index)))\n",
        "\n",
        "        if set_name == \"train\":\n",
        "            idx_used = train_index\n",
        "        elif set_name == \"val\":\n",
        "            idx_used = val_index\n",
        "        else:\n",
        "            raise ValueError(\"set_name can only be 'train' or 'val'\")\n",
        "\n",
        "        self.imgList_used = np.array(self.imageList)[idx_used.astype(np.int)]\n",
        "        self.lbList_used = np.array(self.labelList)[idx_used.astype(np.int)]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imgList_used)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_path, lb_path = self.imgList_used[index], self.lbList_used[index]\n",
        "\n",
        "        if img_path.split('.')[-1] == \"tif\":\n",
        "            img_ds = gdal.Open(img_path)\n",
        "            img = img_ds.ReadAsArray()\n",
        "            del img_ds\n",
        "        else:\n",
        "            img = np.array(Image.open(img_path)).transpose(2, 0, 1)\n",
        "        lb = np.array(Image.open(lb_path))\n",
        "\n",
        "        img = img/img.max()\n",
        "\n",
        "        unified_size = 256\n",
        "        if self.set_name == \"train\":\n",
        "            if img.shape[1]>unified_size:\n",
        "                uly, ulx = random.randint(0, img.shape[1]-unified_size), random.randint(0, img.shape[2]-unified_size)\n",
        "                img = img[:, uly:uly+unified_size, ulx:ulx+unified_size]\n",
        "                lb = lb[uly:uly+unified_size, ulx:ulx+unified_size]\n",
        "            elif img.shape[1]<unified_size:\n",
        "                size_y, size_x = img.shape[1], img.shape[2]\n",
        "                img = cv2.copyMakeBorder(img.transpose(1, 2, 0), 0, unified_size-size_y, 0, unified_size-size_x, cv2.BORDER_CONSTANT, value=(0, 0, 0)).transpose(2, 0, 1)\n",
        "                lb = cv2.copyMakeBorder(lb, 0, unified_size-size_y, 0, unified_size-size_x, cv2.BORDER_CONSTANT, value=0)\n",
        "\n",
        "        return torch.as_tensor(img, dtype=torch.float), torch.as_tensor(lb, dtype=torch.int64)\n",
        "\n",
        "\n",
        "class myDataset_test(data.Dataset):\n",
        "    def __init__(self, data_path):\n",
        "        self.imgList = [i.path for i in os.scandir(data_path) if i.name.split('.')[-1]]\n",
        "        self.imgList.sort()\n",
        "        self.imgNameList = [i.split('/')[-1] for i in self.imgList]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imgList)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_path = self.imgList[index]\n",
        "        if img_path.split('.') == \"tif\":\n",
        "            img_ds = gdal.Open(img_path)\n",
        "            img = img_ds.ReadAsArray()\n",
        "            del img_ds\n",
        "        else:\n",
        "            img = np.array(Image.open(img_path)).transpose(2, 0, 1)\n",
        "\n",
        "        img = img/img.max()\n",
        "        return torch.as_tensor(img, dtype=torch.float)\n",
        "\n",
        "\n",
        "def getDataLoader(dataPath, setName, shuffle=True, BSize=4, nWorkers=4, pinMem=True):\n",
        "    if setName in [\"train\", \"val\"]:\n",
        "        data_set = myDataset(dataPath, setName)\n",
        "        return data.DataLoader(data_set, batch_size=BSize, shuffle=shuffle, num_workers=nWorkers, pin_memory=pinMem)\n",
        "\n",
        "    elif setName == \"test\":\n",
        "        data_set = myDataset_test(dataPath)\n",
        "        return data.DataLoader(data_set, batch_size=BSize, shuffle=False, num_workers=nWorkers, pin_memory=pinMem)\n",
        "\n",
        "    else:\n",
        "        raise ValueError(\"setName can only be 'train', 'val' or 'test'\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "fee75cd8-41a4-4e26-bfa8-de370640a3f1",
        "_cell_guid": "dfd05408-2ab5-43bb-891c-14041af0ee64",
        "trusted": true,
        "id": "NIbRSWh8FAOz"
      },
      "cell_type": "code",
      "source": [
        "class Resblock(nn.Module):\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    def __init__(self, in_ch, out_ch, stride=1):\n",
        "        super().__init__()\n",
        "        self.ch_asc = (in_ch != out_ch)\n",
        "        mid_ch = out_ch//4\n",
        "        self.conv = nn.Sequential(nn.Conv2d(in_ch, mid_ch, 1, 1, padding=0), nn.BatchNorm2d(mid_ch), nn.ReLU(),\n",
        "                                  nn.Conv2d(mid_ch, mid_ch, 3, stride, padding=1), nn.BatchNorm2d(mid_ch), nn.ReLU(),\n",
        "                                  nn.Conv2d(mid_ch, out_ch, 1, 1, padding=0), nn.BatchNorm2d(out_ch))\n",
        "        if self.ch_asc:\n",
        "            self.shortcut = nn.Sequential(nn.Conv2d(in_ch, out_ch, 1, 1, 0), nn.BatchNorm2d(out_ch))\n",
        "\n",
        "    def forward(self, x_in):\n",
        "        x = self.conv(x_in)\n",
        "        if self.ch_asc:\n",
        "            return F.relu(x + self.shortcut(x_in))\n",
        "        else:\n",
        "            return F.relu(x + x_in)\n",
        "\n",
        "class myModel(nn.Module):\n",
        "\n",
        "    def __init__(self, in_ch=3, n_classes=2):\n",
        "        self.n_classes = n_classes\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Sequential(nn.Conv2d(in_ch, 64, 3, stride=2, padding=1), nn.BatchNorm2d(64), nn.ReLU(),\n",
        "                                   nn.Conv2d(64, 64, 3, stride=1, padding=1), nn.BatchNorm2d(64), nn.ReLU())\n",
        "        self.conv2 = nn.Sequential(nn.MaxPool2d(3, stride=2, padding=1),\n",
        "                                   Resblock(in_ch=64, out_ch=128),\n",
        "                                   Resblock(in_ch=128, out_ch=128))\n",
        "        self.conv3 = nn.Sequential(nn.MaxPool2d(2, stride=2, padding=0),\n",
        "                                   Resblock(in_ch=128, out_ch=128),\n",
        "                                   Resblock(in_ch=128, out_ch=256))\n",
        "        self.conv4 = nn.Sequential(Resblock(in_ch=256, out_ch=256),\n",
        "                                   Resblock(in_ch=256, out_ch=512))\n",
        "        self.conv5 = nn.Sequential(Resblock(in_ch=512, out_ch=512),\n",
        "                                   Resblock(in_ch=512, out_ch=512))\n",
        "        self.up = nn.Sequential(nn.ConvTranspose2d(512, 256, 2, stride=2, padding=0), nn.BatchNorm2d(256), nn.ReLU(),\n",
        "                                nn.ConvTranspose2d(256, 128, 2, stride=2, padding=0), nn.BatchNorm2d(128), nn.ReLU(),\n",
        "                                nn.ConvTranspose2d(128, 64, 2, stride=2, padding=0), nn.BatchNorm2d(64), nn.ReLU(),\n",
        "                                nn.Conv2d(64, 32, 3, stride=1, padding=1), nn.BatchNorm2d(32), nn.ReLU(),\n",
        "                                nn.Conv2d(32, n_classes, 1, stride=1, padding=0))\n",
        "\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        inputs = self.conv1(inputs)\n",
        "        inputs = self.conv2(inputs)\n",
        "        inputs = self.conv3(inputs)\n",
        "        inputs = self.conv4(inputs)\n",
        "        inputs = self.conv5(inputs)\n",
        "\n",
        "        outputs = self.up(inputs)\n",
        "        return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "627a8b76-f4d9-4b97-888b-d7727365c584",
        "_cell_guid": "3a52ab8a-d289-4d92-93cc-ab5d2bf401bf",
        "trusted": true,
        "id": "DbA7-yJ7FAO2"
      },
      "cell_type": "code",
      "source": [
        "def dice_coef(pred, label):\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    assert(pred.shape == label.shape)\n",
        "    batchSize = pred.shape[0]\n",
        "    pred, label = pred.view(batchSize, -1), label.view(batchSize, -1)\n",
        "    TP = torch.sum(pred * label, dim=1).float()\n",
        "    return 2 * TP / (torch.sum(pred, dim=1).float() + torch.sum(label, dim=1).float() + 0.00000001)\n",
        "\n",
        "@nb.njit\n",
        "def encodePixel(binaryMap):\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    assert len(binaryMap.shape) == 2\n",
        "    binaryMap = binaryMap.reshape(-1)\n",
        "    totalPixNum = binaryMap.shape[0]\n",
        "    encodedStr = \"\"\n",
        "    flag = 0\n",
        "    count = 0\n",
        "    for i in range(totalPixNum):\n",
        "        if (binaryMap[i] == 1) and (flag == 0) and (i < totalPixNum-1):\n",
        "            encodedStr += str(i+1)\n",
        "            encodedStr += \" \"\n",
        "            flag = 1\n",
        "            count += 1\n",
        "        elif (binaryMap[i] == 0) and (flag == 1):\n",
        "            encodedStr += str(count)\n",
        "            encodedStr += \" \"\n",
        "            count = 0\n",
        "            flag = 0\n",
        "        elif (binaryMap[i] == 1) and (flag == 1) and (i < totalPixNum-1):\n",
        "            count += 1\n",
        "        elif (binaryMap[i] == 1) and (flag == 1) and (i == totalPixNum-1):\n",
        "            encodedStr += str(count)\n",
        "            encodedStr += \" \"\n",
        "            count = 0\n",
        "            flag = 0\n",
        "        elif (binaryMap[i] == 1) and (flag == 0) and (i == totalPixNum-1):\n",
        "            encodedStr += str(i+1)\n",
        "            encodedStr += \" 1 \"\n",
        "\n",
        "\n",
        "    return encodedStr[:-1]\n",
        "\n",
        "\n",
        "def train(model, train_loader, val_loader, lr_base, epoch, device=torch.device('cpu:0'), comment=\"xxx\", ckpt_path=\"./CKPT/\", from_scrach=False):\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    model.to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr_base)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, mode='min', factor=0.8, patience=1,\n",
        "                                                     min_lr=0.000001, threshold=0.0001)\n",
        "    criteria = nn.CrossEntropyLoss()\n",
        "    ckpt_path = ckpt_path + \"/\" + comment\n",
        "\n",
        "    if os.path.exists(ckpt_path + \"/ckpt.pth\") and (not from_scrach):\n",
        "        ckpt = torch.load(ckpt_path + \"/ckpt.pth\", map_location=torch.device('cpu'))\n",
        "        model.load_state_dict(ckpt[\"model\"])\n",
        "        optimizer.load_state_dict(ckpt[\"optimizer\"])\n",
        "        scheduler.load_state_dict(ckpt[\"scheduler\"])\n",
        "        ep_start = ckpt[\"epoch\"]\n",
        "        iter_start = ckpt[\"iteration\"]\n",
        "    else:\n",
        "        ep_start = 0\n",
        "        iter_start = 0\n",
        "\n",
        "    for ep in range(ep_start + 1, epoch + 1):\n",
        "        with tqdm(enumerate(train_loader), desc=\"epoch %3d/%-3d\" % (ep, epoch), total=len(train_loader)) as t:\n",
        "            for batch_idx, (img_train, lb_train) in t:\n",
        "                img_train, lb_train = img_train.to(device), lb_train.to(device)\n",
        "                model.train()\n",
        "                logits = model(img_train)\n",
        "                loss_train = criteria(input=logits, target=lb_train)\n",
        "                optimizer.zero_grad()\n",
        "                loss_train.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    n_iter = (ep - 1) * len(train_loader) + batch_idx\n",
        "                    pred = torch.argmax(F.softmax(logits, dim=1), dim=1)\n",
        "                    dice_train = torch.mean(dice_coef(pred, lb_train))\n",
        "\n",
        "                    if (batch_idx in [len(train_loader)-1, (len(train_loader)//2)]) or n_iter == iter_start:\n",
        "                        model.eval()\n",
        "                        dice_val_all = []\n",
        "                        for index_v, (img_val, lb_val) in enumerate(val_loader):\n",
        "                            img_val, lb_val = img_val.to(device), lb_val.to(device)\n",
        "                            pred = torch.argmax(F.softmax(model(img_val), dim=1), dim=1)\n",
        "                            dice_val_all.append(dice_coef(pred, lb_val))\n",
        "                        dice_val_all = torch.cat(dice_val_all, dim=0)\n",
        "                        dice_val = torch.mean(dice_val_all)\n",
        "\n",
        "                t.set_postfix_str(\"loss(train): %.4f, dice(train): %.4f, dice(val): %.4f, lr: %f\"\n",
        "                                  % (loss_train, dice_train, dice_val,\n",
        "                                     optimizer.state_dict()['param_groups'][0]['lr']))\n",
        "\n",
        "        scheduler.step(dice_val)\n",
        "\n",
        "        if not os.path.exists(ckpt_path):\n",
        "            os.mkdir(ckpt_path)\n",
        "        torch.save({'epoch': ep,\n",
        "                    'iteration': ep * len(train_loader),\n",
        "                    'model': model.state_dict(),\n",
        "                    'optimizer': optimizer.state_dict(),\n",
        "                    'scheduler': scheduler.state_dict(),\n",
        "                    }, ckpt_path + \"/ckpt.pth\")\n",
        "\n",
        "\n",
        "def inference(model, data_loader, ckpt_path, comment, save_path, device=torch.device('cpu:0')):\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    ckpt_path = ckpt_path + \"/\" + comment\n",
        "\n",
        "    if os.path.exists(ckpt_path + \"/ckpt.pth\"):\n",
        "        ckpt = torch.load(ckpt_path + \"/ckpt.pth\", map_location=torch.device('cpu'))\n",
        "        model.load_state_dict(ckpt[\"model\"])\n",
        "        model.to(device)\n",
        "\n",
        "        fnList, encodedPixelList = [\"ID\"], [\"Prediction\"]\n",
        "        with tqdm(enumerate(data_loader), desc=\"Inferencing\" , total=len(data_loader)) as t:\n",
        "            for batch_idx, img in t:\n",
        "                img = img.to(device)\n",
        "                model.eval()\n",
        "                with torch.no_grad():\n",
        "                    if (img.shape[2] % 8 + img.shape[3] % 8) == 0:\n",
        "                        logits = model(img)\n",
        "                        pred = torch.argmax(F.softmax(logits, dim=1), dim=1)\n",
        "                    else:\n",
        "                        pred = torch.zeros([1, img.shape[2], img.shape[3]], dtype=torch.int, device=device)\n",
        "                        img_tiled = torch.cat([img[:, :, 0:128, 0:128], img[:, :, img.shape[2]-128:, 0:128], img[:, :, 0:128, 35:], img[:, :, img.shape[2]-128:, 35:]], dim=0)\n",
        "                        pred_tiled = torch.argmax(F.softmax(model(img_tiled), dim=1), dim=1)\n",
        "                        pred[0, 0:128, 0:128] = pred_tiled[0, ...]\n",
        "                        pred[0, img.shape[2]-128:, 0:128] = pred_tiled[1, ...]\n",
        "                        pred[0, 0:128, 35:] = pred_tiled[2, ...]\n",
        "                        pred[0, img.shape[2]-128:, 35:] = pred_tiled[3, ...]\n",
        "\n",
        "                pred = pred.cpu().numpy()\n",
        "                fnList.append(data_loader.dataset.imgNameList[batch_idx])\n",
        "                encodedPixelList.append(encodePixel(pred[0]))\n",
        "\n",
        "            pred2submit = np.array(list(zip(fnList, encodedPixelList)))\n",
        "            np.savetxt(save_path, pred2submit, delimiter=\",\", fmt=\"%s\")\n",
        "            print(\"prediction saved to %s\" % save_path)\n",
        "    else:\n",
        "        print(\"Checkpoint not found\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "357dffa0-1cb4-4b37-b888-82e39d9b0e87",
        "_cell_guid": "76b367ba-afb0-41a7-afd3-7aa104c3581e",
        "trusted": true,
        "id": "nGOF-BbCFAO7"
      },
      "cell_type": "code",
      "source": [
        "model = myModel(n_classes=2)\n",
        "trainLoader = getDataLoader(dataPath=DATAPATH + \"/train_data\", setName=\"train\", shuffle=True, BSize=16, nWorkers=2, pinMem=True)\n",
        "valLoader = getDataLoader(dataPath=DATAPATH+\"/train_data\", setName=\"val\", shuffle=False, BSize=16, nWorkers=2, pinMem=True)\n",
        "train(model, trainLoader, valLoader, lr_base=0.001, epoch=20, device=torch.device('cuda:0'), comment=\"foo\", ckpt_path=\"/kaggle/working/\", from_scrach=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "3ddfc12b-5176-4153-8cb3-ac27de535a87",
        "_cell_guid": "5c2461a2-e8d5-4b50-93de-a7833891a01f",
        "trusted": true,
        "id": "2t5Oe769FAO-"
      },
      "cell_type": "code",
      "source": [
        "testImageList = [i.path for i in os.scandir(DATAPATH+\"/test_image\")]\n",
        "model = model.to(torch.device(\"cuda:0\"))\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i in range(0, len(testImageList), 50):\n",
        "        img = cv2.imread(testImageList[i], -1).transpose(2, 0, 1)\n",
        "        img = img/img.max()\n",
        "        img = torch.as_tensor(img.reshape(1, 3, img.shape[1], img.shape[2]), dtype=torch.float).cuda()\n",
        "        pred = torch.argmax(torch.softmax(model(img), dim=1), dim=1).cpu().numpy()[0, :, :]\n",
        "        plt.figure(figsize=(10, 20))\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.imshow(img.cpu().numpy().reshape(3, img.shape[2], img.shape[3]).transpose(1, 2, 0))\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.imshow(pred)\n",
        "        plt.show()\n",
        "        if i>500:\n",
        "            break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "8SbVewi5FAPE"
      },
      "cell_type": "code",
      "source": [
        "testLoader = getDataLoader(dataPath=DATAPATH + \"/test_image\", setName=\"test\", shuffle=False, BSize=1, nWorkers=2, pinMem=True)\n",
        "inference(model, data_loader=testLoader, ckpt_path=\"/kaggle/working/\", comment=\"foo\", save_path=\"/kaggle/working/prediction.csv\", device=torch.device('cuda:0'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "fLrCApgRFAPG"
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(r\"/kaggle/working/prediction.csv\")\n",
        "print(\"\"%len(df))\n",
        "df.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "3JSuRo7-FAPG"
      },
      "cell_type": "code",
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}